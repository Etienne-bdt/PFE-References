@inproceedings{aziziCoupledVAEInterpolator2024,
  title = {Coupled {{VAE}} and {{Interpolator Approach}} for {{Fast Hyperspectral Image Emulation}}},
  booktitle = {2024 14th {{Workshop}} on {{Hyperspectral Imaging}} and {{Signal Processing}}: {{Evolution}} in {{Remote Sensing}} ({{WHISPERS}})},
  author = {Azizi, Chedly Ben and Guilloteau, Claire and Roussel, Gilles and Puigt, Matthieu},
  year = {2024},
  pages = {1--5},
  publisher = {IEEE},
  note = {Cocorico, ce papier parle d'un VAE o{\`u} l'on remplace l'encodeur par un r{\'e}seau 'interpolateur' qui vient projeter des variables biophysiques dans l'espace latent apr{\`e}s avoir entrain{\'e} le VAE pour de la reconstruction. Le d{\'e}codeur est frozen pour la deuxi{\`e}me partie.}
}

@inproceedings{dortaStructuredUncertaintyPrediction2018,
  title = {Structured Uncertainty Prediction Networks},
  booktitle = {Proceedings of the {{IEEE}} Conference on Computer Vision and Pattern Recognition},
  author = {Dorta, Garoe and Vicente, Sara and Agapito, Lourdes and Campbell, Neill DF and Simpson, Ivor},
  year = {2018},
  pages = {5477--5485},
  note = {Am{\'e}lioration des VAE en apprenant une variance plus complexe et creuse en utilisant cholesky. Cela am{\'e}liore les {\'e}chantillons mais au prix d'une petite quantit{\'e} de calculs en plus. Il est aussi propos{\'e} une fa{\c c}on plus performante {\`a} l'aide d'une distance de mahalanobis et de normalisation spectrale : regarder la distance entre la classe la plus proche et la pr{\'e}diction (pas pertinent ici)}
}

@article{dumeurSelfsupervisedSpatiotemporalRepresentation2024,
  title = {Self-Supervised Spatio-Temporal Representation Learning of {{Satellite Image Time Series}}},
  author = {Dumeur, Iris and Valero, Silvia and Inglada, Jordi},
  year = {2024},
  journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  volume = {17},
  pages = {4350--4367},
  publisher = {IEEE},
  note = {Mod{\`e}le inspir{\'e} de BERT. U-BARN {$\rightarrow$} Encodeur Spatial et Spectral. L'image est divis{\'e}e en patches qui sont encod{\'e}s puis reconstruits par un U-NET. Les sorties des Unets sont ensuite embedd{\'e}es par position pour {\^e}tre ensuite donn{\'e}es {\`a} un transformer. L'id{\'e}e est d'ensuite d'ajouter une t{\^a}che (classif/segmentation, reconstruction) {\`a} la fin du U-BARN pour pouvoir l'entrainer {\`a} une t{\^a}che pr{\'e}cise. Probl{\`e}me : pas un VAE, les repr{\'e}sentations sont un espace de petite dimension mais pas probabiliste. Quid des incertitudes ? Autre question : les patches introduisent une limite dans la spatialit{\'e} de la donn{\'e}e, on reste local. Le c{\^o}t{\'e} temporel traverse les patchs embeddings : chaque instant de prise de vue passe dans un SSE. On reshape les SITS en b*t,c,h,w puis en b x w x h ,t ,d avant le transformer}
}

@article{gatopoulosSuperresolutionVariationalAutoencoders2020,
  title = {Super-Resolution Variational Auto-Encoders},
  author = {Gatopoulos, Ioannis and Stol, Maarten and Tomczak, Jakub M},
  year = {2020},
  journal = {arXiv preprint arXiv:2006.05218},
  eprint = {2006.05218},
  archiveprefix = {arXiv},
  note = {Construit sur {\textbackslash}citesohn2015Learning. Utilisation d'une image LR pour sampler un premier {\'e}tage de variables latentes u, puis samplage de z avec u et y et finalement x {\textbar} z. Papier qui n'entraine que sur des imagettes de 32*32 {\textbar} 64*64 car peu de puissance de calcul. Possibilit{\'e} d'am{\'e}lioration en 256*256 ??}
}

@misc{heynsRetorquereZoterobetterbibtex2025,
  title = {Retorquere/Zotero-Better-Bibtex},
  author = {Heyns, Emiliano},
  year = {2025},
  month = apr,
  urldate = {2025-04-23},
  abstract = {Make Zotero effective for us LaTeX holdouts},
  copyright = {MIT}
}

@article{maudDeepPriorsSatellite2024,
  title = {Deep Priors for Satellite Image Restoration with Accurate Uncertainties},
  author = {Maud, Biquard and Chabert, Marie and Genin, Florence and Latry, Christophe and Oberlin, Thomas},
  year = {2024},
  journal = {arXiv preprint arXiv:2412.04130},
  eprint = {2412.04130},
  archiveprefix = {arXiv},
  note = {VBLE, utilisation d'une architecture CAE, proche d'un VAE qui estime un hyperprior {\`a} partir de {\textbackslash}barz. On peut donc sampler z {\`a} partir de l'hyperprior puis le d{\'e}coder pour obtenir la moyenne et la variance (en utilisant deux d{\'e}codeurs). Voir {\textbackslash}citerybkin2021simple concernant la m{\'e}thode. Comment mesurer incertitude ? Ici, pour un pixel, on sample 100 fois l'image et on regarde le pourcentage de fois o{\`u} la valeur du pixel est dans la valeur du nouveau sample {\textbackslash}pm5\% ?}
}

@inproceedings{prostEfficientPosteriorSampling2024,
  title = {Efficient {{Posterior Sampling For Diverse Super-Resolution}} with {{Hierarchical VAE Prior}}},
  booktitle = {{{VISAPP}} 2024-19th {{International Conference}} on {{Computer Vision Theory}} and {{Applications}}},
  author = {Prost, Jean and Houdard, Antoine and Almansa, Andr{\'e}s and Papadakis, Nicolas},
  year = {2024},
  note = {Dans ce papier, on a un VAE hi{\'e}rarchique conditionnel en quelque sorte. l'id{\'e}e est que les variables latentes donn{\'e}es par l'encodeur low-res captent les d{\'e}tails basse fr{\'e}quences et que conditionn{\'e} selon ca, on peut ensuite sampler les variables latentes pour ensuite sampler une version High-res en la passant dans notre mod{\`e}le g{\'e}n{\'e}ratif : \$\$. L'id{\'e}e est qu'on va contraindre les k premi{\`e}res variables latentes de l'encodeur HR et LR {\`a} correspondre en distribution (via une divergence KL) ce qui essaye de contraindre l'espace latent de capturer une repr{\'e}sentation BF/LR de l'image. Implem : tu prends un VDVAE et {\`a} chaque {\'e}tage tu viens calculer des moyennes et variances pour les var latentes ?}
}

@inproceedings{rybkinSimpleEffectiveVAE2021,
  title = {Simple and Effective {{VAE}} Training with Calibrated Decoders},
  booktitle = {International Conference on Machine Learning},
  author = {Rybkin, Oleh and Daniilidis, Kostas and Levine, Sergey},
  year = {2021},
  pages = {9179--9189},
  publisher = {PMLR},
  note = {Ici, l'id{\'e}e est de trouver des m{\'e}thodes plus faciles/efficaces d'utiliser un VAE. La m{\'e}thode cl{\'e} propos{\'e}e est par exemple de calculer la variance selon les donn{\'e}es et de sortir la moyenne via un r{\'e}seau de neurones. NB : La revue par les pairs est relativement mitig{\'e}e sur l'int{\'e}r{\^e}t du papier.}
}

@article{sheMAGICModularAutoencoder2024,
  title = {{{MAGIC}}: {{Modular Auto-encoder}} for {{Generalisable Model Inversion}} with {{Bias Corrections}}},
  author = {She, Yihang and Atzberger, Clement and Blake, Andrew and Gualandi, Adriano and Keshav, Srinivasan},
  year = {2024},
  journal = {arXiv preprint arXiv:2405.18953},
  eprint = {2405.18953},
  archiveprefix = {arXiv},
  note = {Utilisation d'un AE classique o{\`u} le d{\'e}codeur est remplac{\'e} par un mod{\`e}le physique en pytorch. Adaptabilit{\'e} avec un VAE pour faire de la g{\'e}n{\'e}ration ? Probl{\`e}me, on perd la partie p(x{\textbar}z). R{\'e}seau lin{\'e}aire, pertinence ? Les variables ont plus de sens physique mais m{\^e}me perf qu'un AE classique sur ce probl{\`e}me. Cit{\'e} une fois {\`a} la r{\'e}daction de ce document.}
}

@article{sohnLearningStructuredOutput2015,
  title = {Learning Structured Output Representation Using Deep Conditional Generative Models},
  author = {Sohn, Kihyuk and Lee, Honglak and Yan, Xinchen},
  year = {2015},
  journal = {Advances in neural information processing systems},
  volume = {28},
  note = {Conditionnement d'un VAE avec une entr{\'e}e suppl{\'e}mentaire (typiquement un label) pour conditionner le mod{\`e}le dans l'espace latent}
}

@inproceedings{vazhentsevUncertaintyEstimationTransformer2022,
  title = {Uncertainty Estimation of Transformer Predictions for Misclassification Detection},
  booktitle = {Proceedings of the 60th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Vazhentsev, Artem and Kuzmin, Gleb and Shelmanov, Artem and Tsvigun, Akim and Tsymbalov, Evgenii and Fedyanin, Kirill and Panov, Maxim and Panchenko, Alexander and Gusev, Gleb and Burtsev, Mikhail and others},
  year = {2022},
  pages = {8237--8252},
  note = {Estimation d'incertitudes d'un transformer en utilisant du dropout pendant l'inf{\'e}rence. En droppant quelques neurones, on peut venir sampler la distribution estim{\'e}e de la sortie et donc avoir une id{\'e}e de l'incertitude.}
}

@phdthesis{zerahPhysicsbasedDeepRepresentation2024,
  title = {Physics-Based Deep Representation Learning of Vegetation Using Optical Satellite Image Time Series},
  author = {Z{\'e}rah, Yo{\"e}l},
  year = {2024},
  school = {Universit{\'e} de Toulouse},
  note = {Utilisation d'un mod{\`e}le physique comme d{\'e}codeur d'un VAE pour donner de l'interpr{\'e}tabilit{\'e} aux variables latentes. Les variables latentes sont s{\'e}par{\'e}es en deux parties (vecteurs coup{\'e}s en deux) une partie d{\'e}codeur 'al{\'e}atoire', une partie mod{\`e}le physique d{\'e}terministe. Une contrainte de reconstruction, MCRL : {\textbackslash}mathcalL\_MCRL = -ln(p(x\_i{\textbar}z\_i)) permet notamment d'avoir une moyenne proche des x\_i et une variance {\textbackslash}hat{\textbackslash}sigma{$^{2}\_$}i qui repr{\'e}sente l'incertitude du d{\'e}codeur.}
}
